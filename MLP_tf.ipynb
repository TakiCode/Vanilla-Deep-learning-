{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 104,690\n",
      "Trainable params: 104,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.8283 - acc: 0.7478 - val_loss: 0.3432 - val_acc: 0.9043\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.4068 - acc: 0.8807 - val_loss: 0.2572 - val_acc: 0.9265\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.3287 - acc: 0.9047 - val_loss: 0.2170 - val_acc: 0.9391\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2819 - acc: 0.9174 - val_loss: 0.1892 - val_acc: 0.9457\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2516 - acc: 0.9267 - val_loss: 0.1711 - val_acc: 0.9507\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2301 - acc: 0.9323 - val_loss: 0.1564 - val_acc: 0.9551\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.2131 - acc: 0.9377 - val_loss: 0.1457 - val_acc: 0.9567\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1971 - acc: 0.9428 - val_loss: 0.1355 - val_acc: 0.9584\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1819 - acc: 0.9469 - val_loss: 0.1296 - val_acc: 0.9612\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1731 - acc: 0.9490 - val_loss: 0.1214 - val_acc: 0.9638\n",
      "Test loss: 0.1213930520966649\n",
      "Test accuracy: 0.9638\n"
     ]
    }
   ],
   "source": [
    "# SÃ©quentiel\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot))\n",
    "score = model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model subclassing\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.dense1 = Dense(120,activation='relu',input_shape=(784,))\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "        self.dense2 = Dense(80, activation='relu')\n",
    "        self.dropout2 = Dropout(0.2)\n",
    "        self.dense3 = Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return self.dense3(x)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # You need to override this function if you want to use the subclassed model\n",
    "        # as part of a functional-style model.\n",
    "        # Otherwise, this method is optional.\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape = [shape[0], self.num_classes]\n",
    "        print(shape)\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mlp2 = MLP()\n",
    "my_mlp2.compile(optimizer=tf.keras.optimizers.SGD(),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.8239 - accuracy: 0.7512 - val_loss: 0.3323 - val_accuracy: 0.9106\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.4016 - accuracy: 0.8810 - val_loss: 0.2530 - val_accuracy: 0.9279\n",
      "Test loss: 302.190838671875\n",
      "Test accuracy: 0.10360000282526016\n"
     ]
    }
   ],
   "source": [
    "history = my_mlp2.fit(x_train,y_train_one_hot,batch_size=32,epochs=2, validation_data=(x_test, y_test_one_hot))\n",
    "score = my_mlp2.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"Test loss: {}\".format(score[0]))\n",
    "print(\"Test accuracy: {}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "sgd = tf.keras.optimizers.SGD()\n",
    "my_mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_class(predictions):\n",
    "    return np.argmax(predictions,axis = 1)\n",
    "\n",
    "def score(y_true,predictions):\n",
    "    predictions = mlp_class(predictions)\n",
    "    return np.sum(y_true == predictions)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Tape\n",
    "@tf.function\n",
    "def train(data,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = my_mlp(data)\n",
    "        loss = loss_object(labels,predictions)\n",
    "    gradients = tape.gradient(loss, my_mlp.trainable_variables)\n",
    "    sgd.apply_gradients(zip(gradients,my_mlp.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "iterations = 60000//BATCH_SIZE\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for iteration in range(iterations):\n",
    "        train(x_train[BATCH_SIZE*(iteration-1):BATCH_SIZE*(iteration),:],\n",
    "              y_train_one_hot[BATCH_SIZE*(iteration-1):BATCH_SIZE*(iteration),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1231866106390953\n",
      "Accuracy: 0.9642\n"
     ]
    }
   ],
   "source": [
    "predictions = my_mlp(x_test)\n",
    "error = loss_object(y_test_one_hot,predictions)\n",
    "accuracy = score(y_test,predictions)\n",
    "print(\"Test loss: {}\".format(error))\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
